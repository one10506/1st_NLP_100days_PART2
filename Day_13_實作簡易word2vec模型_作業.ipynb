{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import clip_grads, convert_one_hot, preprocess, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 7, 6, 5, 4]),\n",
       " array([[3, 2],\n",
       "        [1, 7],\n",
       "        [2, 6],\n",
       "        [7, 5],\n",
       "        [6, 4],\n",
       "        [5, 0]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "    \n",
    "    contexts = corpus[window_size:-window_size]\n",
    "    targets = []\n",
    "\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                # skip target word itself\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        targets.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets= create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0]], dtype=int32),\n",
       " array([[[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]],\n",
       " \n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0]]], dtype=int32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "### <your code> ###\n",
    "contexts = convert_one_hot(contexts,len(word2idx))\n",
    "targets = convert_one_hot(targets,len(word2idx))\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in)\n",
    "        self.out_layer = Dense(W_out)\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size * 2)]#輸出層的loss function\n",
    "        \n",
    "\n",
    "        layers = [self.in_layer,self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts)\n",
    "        s = self.out_layer.forward(h)\n",
    "        \n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size * 2)])\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size * 2)])\n",
    "        dh = self.out_layer.backward(ds)\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 277/1000 [00:00<00:00, 1148.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.159102253895648\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.159074430211167\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.158833529037984\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.158909165956155\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158838097029035\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.158701381338954\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158700042452905\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158596408621332\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.1585512591544\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.1583702454655\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158286799808709\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.15851634985325\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.158245197119749\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158001782434594\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.158006358166824\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.157830977691435\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.157709165229592\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.157885114736914\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.157242406620566\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.157179858911894\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.1570943103687865\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.1570985363214605\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.156520135253679\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.15648566319401\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.156431327869147\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.155971599019695\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.155045089101062\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.155532458734985\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.155199415441571\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.155380026100321\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.15326295830152\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.1524060977863515\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.153796313057326\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.15211734655836\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.152565323919852\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.152094794070903\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.1494031289394675\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.149350346198853\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.146950588275696\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.146129826386471\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.145119687099998\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.143598901980049\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.143756248571099\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.1363577563473175\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.146349093979881\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.1353074772432485\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.130094277867577\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.137290755701839\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.128633195990231\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.113649123667292\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.120419067677155\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.1112387933766525\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.1109887078488985\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.111096777654645\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.097356954595249\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.115096154012006\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.088496773991434\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.0688709299770895\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.060643956373124\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.07607734199714\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.0688229010311545\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.011322113027955\n",
      "Epoch: 63, Iteration: 1/2, Loss: 4.05301642350855\n",
      "Epoch: 64, Iteration: 1/2, Loss: 4.0111770920445\n",
      "Epoch: 65, Iteration: 1/2, Loss: 3.9761249390875504\n",
      "Epoch: 66, Iteration: 1/2, Loss: 3.991848024237711\n",
      "Epoch: 67, Iteration: 1/2, Loss: 3.97315966982198\n",
      "Epoch: 68, Iteration: 1/2, Loss: 3.927726206086194\n",
      "Epoch: 69, Iteration: 1/2, Loss: 3.8888566887332354\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.8722260136293425\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.8568319685417514\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.939651441712933\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.7591585468223765\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.6913391709543024\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.8290160467436074\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.610168052880824\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.7870616499527543\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.5649885054152457\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.5678174940615572\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.5202170256930176\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.4707204471616775\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.421388511021465\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.346756476675251\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.2521751050409895\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.3392550076841117\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.2659667870590403\n",
      "Epoch: 87, Iteration: 1/2, Loss: 3.153991882652875\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.1488877858696878\n",
      "Epoch: 89, Iteration: 1/2, Loss: 2.8323857481868897\n",
      "Epoch: 90, Iteration: 1/2, Loss: 2.9841519929822677\n",
      "Epoch: 91, Iteration: 1/2, Loss: 3.0336932304891677\n",
      "Epoch: 92, Iteration: 1/2, Loss: 2.8587496646032857\n",
      "Epoch: 93, Iteration: 1/2, Loss: 2.7314439053737125\n",
      "Epoch: 94, Iteration: 1/2, Loss: 2.891634500473566\n",
      "Epoch: 95, Iteration: 1/2, Loss: 2.7538996931238\n",
      "Epoch: 96, Iteration: 1/2, Loss: 2.6590221359229633\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.73737403743808\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.404988731078434\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.557651678602204\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.4700852305685306\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.662607979091011\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.434906126557881\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.3195601953936853\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.2373120278908925\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.424995976703669\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.1946121959326126\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.358172174072615\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.1492635507598594\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.112695713729717\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.132074369182182\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.273907263069665\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.07196760557382\n",
      "Epoch: 113, Iteration: 1/2, Loss: 1.9837312611706777\n",
      "Epoch: 114, Iteration: 1/2, Loss: 2.1223766590037894\n",
      "Epoch: 115, Iteration: 1/2, Loss: 1.9820972095563112\n",
      "Epoch: 116, Iteration: 1/2, Loss: 1.9675211668754675\n",
      "Epoch: 117, Iteration: 1/2, Loss: 1.970699736239417\n",
      "Epoch: 118, Iteration: 1/2, Loss: 2.012097631525612\n",
      "Epoch: 119, Iteration: 1/2, Loss: 1.834767863265276\n",
      "Epoch: 120, Iteration: 1/2, Loss: 1.9043665530592766\n",
      "Epoch: 121, Iteration: 1/2, Loss: 1.866196639861021\n",
      "Epoch: 122, Iteration: 1/2, Loss: 1.9294244804647984\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.8402967928798293\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.8342556856629484\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.8250368871423246\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.8278568572785414\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.793276895344923\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.7360334367195007\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.7955243161258916\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.6692429316550883\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.7648542356125687\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.731484183225258\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.7118342960243542\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.6953032539035984\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.6905561917671426\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.693936650516898\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.6328105400938846\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.6787659352488555\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.6576972427526218\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.645646606987372\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.6841286014821064\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.630274049236136\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.6119371717323583\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.5681755202029855\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.6432542206165306\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.5874600807015156\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.6200864279477751\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.5846142872134088\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.5849691327647755\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.589566627285257\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.5618182219572416\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.5741362768129392\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.5648389001882803\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.5527786872958742\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.5389178692494367\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.5887817574771632\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.5329035413410963\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.565218882038459\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.5168062819420538\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5543926125153125\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.5384115108145546\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5079479581622452\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.5268869261405398\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.544375457343056\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.5060036427727146\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.5142253990640442\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5313727174739804\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.5026139162986314\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.5053867332644602\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.5069784438596692\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.5017903033610143\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.502006807589577\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.4995353963931004\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.4977173483150474\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.4818197095180579\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.517240442239172\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.4808512559633935\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.4767789752153146\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.4921540567057292\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.4813150329006213\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.4957272869444687\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.4933813301170806\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.4710292132412826\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.4657596004887512\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4811152094688074\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.491328876213847\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.4585428482881593\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.4774821804852365\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4746498222729523\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.459758752701946\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4749979707356369\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4703172701608649\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.4627393590120512\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.463315207442283\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.457169849298984\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.4735711247429064\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4509932999875321\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.4686375720726472\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4492853952575901\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.4588978967966746\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.4650419296072856\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.446729722210091\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.4674757635370135\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.4475501895415688\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.4613050536389887\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.4451061902062288\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.4494170636861923\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4450066973538722\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.4544127109880458\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.4562175530554524\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.44201454706917\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.4451723726884644\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.4448994639969923\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.4478816005173276\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4444718376437873\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.448711532386059\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4374879557044795\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4424316266234167\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.4353788750100347\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4429515079196449\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.443386804090752\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4354608882838613\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.4437845965779583\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.4380640187234852\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.4374839343206778\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.4391902882507526\n",
      "Epoch: 227, Iteration: 1/2, Loss: 1.4311134009374822\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.4361750868245406\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.43986396769278\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.4358468191023528\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.4307025956670394\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.437771419737039\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.4376469551109277\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.4289065239292138\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.4323607330393326\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.4343760808911736\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.4327659700317827\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.4272904899273158\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4303918177875943\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4290006019493693\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.430861618612243\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4311968312508008\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4254382681976663\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4315570789224574\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4244756281310855\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4285112423157114\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.4261014682226199\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.4299565034946558\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4230417811465577\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.4302842486893415\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.4224369451621834\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.4248953786846257\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.4207393575471303\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.428659405411444\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.4240486020322924\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4228548720726253\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.423233514130649\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4230745642894584\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.4229088393410754\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.4261571845068421\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4164767884434053\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.423725093074066\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.4224233149904424\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.420117890164171\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.420943853611067\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4205936004042559\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.422916927069768\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.4208830294307455\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.4161960579924284\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4203404106769444\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.421722996243824\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.4180367482079004\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.4161763788791115\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.415911656573219\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.4238098306505602\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.414658771472317\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4176064058194189\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.4173294970233394\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.417147567157428\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.4168943662886637\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.4166155110463423\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.417121333787542\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.4162301657391136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 631/1000 [00:00<00:00, 1399.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 284, Iteration: 1/2, Loss: 1.4151334188910298\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.4164962506527023\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.4155313423681055\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4144842375075493\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4150989440536292\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4155558346004324\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4146441538776615\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.4165293232873082\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.414130384872006\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.4112399545780063\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.413819204366422\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.4116628030328133\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4160683985054896\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.4133149059846382\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4142941840015169\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.408904034041663\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4134040389788165\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.4163907480009872\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.4096610776315122\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4128465201424345\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.409431037472343\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.4135924310477892\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.4115841044267041\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.4120705310261712\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.4131022866796137\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.40936281000588\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.4127229557643415\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4107633467742797\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.4064740175846167\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4121429779307644\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4086515892452434\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.414096475146402\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4078167474842018\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4098371938408727\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.409687643669903\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.411117481905918\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.4083216823161013\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4086765120639382\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4091118490495482\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.4090174368356858\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4093450384990618\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.4080932831025723\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.408556482431891\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.4085503723103447\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.4102507044678092\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.4045930631231638\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.4101108478264832\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4078592073894156\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.4057502452547173\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.4095887845175405\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.407468522568656\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.4069032175659628\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.4092654736982475\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.405306142629268\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.407438136063171\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.40633293955926\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4054692753956937\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.4085000602511002\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.4065071754149727\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4065400463023583\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4057731978678354\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.4053800739659916\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4069573183900923\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.4065823900215089\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.4054041114011078\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.4062569421676332\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4037586054721816\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4087037196038494\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.4055646896642568\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.4034706211261243\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.4058223640729612\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4051592942037952\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.4063384147854898\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.403105262900662\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.4036966781629214\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.4064307107866318\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.403405142081641\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4058772533986075\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.4040855625124742\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.4030883005403139\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.4059585594990458\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.402434979004251\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.4053737549854333\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.403235105148223\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.403558854378458\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4053946032289515\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.4037427262926774\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4044112860883877\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4012904329642808\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4050094703836549\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.4022473557897532\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.4041709230430288\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4035807579345707\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4026314286152697\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4042491849153693\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.4019154987548816\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.4021411848947758\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4035489583793324\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.4020341640714753\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.4033836570684035\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.4025279531969668\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.4029519008867453\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4020590167798384\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.4023572183548927\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.4022870048208995\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.40220714461717\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4014544941598999\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.402749583005145\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.4008914743719791\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.4040441204117609\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.400823651260635\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4032065903395874\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.401594091632764\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.4007310522070986\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4013959994305019\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.4006022556963633\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.4021848765112026\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4002080330105842\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.4013012819506505\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4022061254110494\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.4005965311001765\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.4017289418101366\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.4001179606283622\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.4022192675757204\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.3999512028168288\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.402690184602423\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.3999428899730988\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.400320743837078\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.399763636724268\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.4018676210976062\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.4000886082744968\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.3996541695062352\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.4012928410282046\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.399484148257511\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.4014727374613236\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.4001263920799343\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.401128515342537\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.3989569394158883\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.3992145027079363\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.401987238767183\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.3990092753403807\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.4000470310070074\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.40070289608984\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.3977244468363526\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.4007507297275281\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.3989145640294713\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.4004732643577436\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.3993635430877767\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.399758206570192\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.3992061565318084\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.4004861254755552\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.3993481455385095\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.3983095153913343\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.400124862296403\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.3983819244865296\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.39837009923813\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.398861085171108\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.4000612959509027\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.3987902645238877\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.3988478469437386\n",
      "Epoch: 444, Iteration: 1/2, Loss: 1.3992371821555576\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.3977266986721628\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.4006840765859263\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.3969848708784092\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.3986113954554407\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.3997663462517433\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.3993583128586606\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.3978917793686267\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.3984192823759756\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.3982499446774075\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.3995063776268424\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.3976205181510064\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.398995180437632\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.397417446920568\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.3984772850331515\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3982051990541389\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.3981613540576396\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.397089486359098\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.3991038057228635\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.3978074238039022\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.398051254530455\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3973168911443392\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.398313933479587\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.3980236081617639\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.397260972633878\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.398254878643885\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3969672153333508\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.39780065085996\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.3992326865255649\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.395956177539086\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.3985720729309317\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.397335839021598\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3977616416767447\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3980662749394852\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3967559853488072\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.3971577931129109\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.3973445538007607\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.3981831514161984\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.3966840921433346\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.397809955259702\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3966140708552723\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.3975254398264594\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.396546329099598\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3976505881074988\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.396323650410149\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.3977287245790722\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.3969728736629436\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.3965750138660455\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3968423292016734\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.3968301072334373\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.3966690499532262\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.396855602780485\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.3968617919667192\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.3961224371354417\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.3971157388532491\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3969196701626654\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.39648464521157\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3964091815431319\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.3968748115162781\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.396443270397556\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3956329424816538\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.3967288268960343\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.3968229788601816\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.396612529466487\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3961722738022837\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.3965714875132447\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3956292274190603\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.396917228170669\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3962444204653108\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.3961422913895336\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.3959856285118692\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.395541588980794\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.396671595346537\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.396346900237293\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.3958084140453813\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3961952894729959\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.396358848522715\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.396119514746871\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.3946280752850948\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3972021554943357\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.394741274345185\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.3964018853901283\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.3963476035891946\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.395057389711944\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.3956930798422946\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.3957775938586094\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.3956920164037179\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.3956635274929141\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.396183052235261\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.3952910742425473\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3954232403399924\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3956640707771277\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.3947276463059053\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.396050686048241\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.3955111262787803\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.3948526553953442\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.39601842059926\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.3960699327838846\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3952086644583734\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3950300884865814\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3951578090943906\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3946895008170468\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.3959558986816747\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3951437757612846\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.3950544562320544\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.3952328065985857\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.395329415907374\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3951801589035537\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3955408653788708\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.3938305568268472\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.395698010676508\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.3950251747011262\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3955770729099846\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3950591230923846\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.3947242050527076\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.3945867373311676\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.3953972504890408\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.3942280309917767\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.3950778408714268\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.3947629330876707\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.395280870001899\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.3938211215366398\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3952484207660332\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.3952052277494489\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.3936087364218848\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.395654352650296\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.3937070110645737\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.3950572220835555\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.3946211063609208\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3941897947240527\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3950653717554444\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3945532175796247\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.3951200518706366\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.3938531889306316\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3944719504456649\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.3944784523222973\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3944937486356754\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.3945642736213002\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3937910462168752\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.394523245241408\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3951299250845604\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.394541693944519\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.3938404817000314\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.3940466695697058\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.3943980924316441\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.3943624686045997\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.3940365425927117\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.394155962311257\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3944267235082501\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.3946253511887736\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.3934812889211525\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.3936315595917539\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.3947637305065834\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.3941336577329946\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.3944240067318445\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3936181121315123\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3940878784923405\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.3943606267900575\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3936270290299744\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3943954865243433\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.393018210595445\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.3944205651740753\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.3932779974233105\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3948788383660324\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.392878776900743\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.3938501102219512\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3939648001385636\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.3938119618657272\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.3946357036846768\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.393364708990402\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.393594541380366\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.3939421235509832\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.3936675512918377\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.3931532581949317\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3940936448447045\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3931764374677578\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3940545770724801\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.3937552019233914\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.393551231708066\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3936376280398148\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.3939168720006836\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.3932149724619038\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.393641305110605\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3933325835127421\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3941010012548154\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.3934091056409414\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.3930773011933641\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.3932792331178177\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3930211922752305\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3943770603626413\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3929030239541955\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.393537096562915\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.3928156101492783\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.3938465665203537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1653.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 638, Iteration: 1/2, Loss: 1.3928165955778067\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.3942182543988615\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3932802841448781\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.392770733919729\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.3932312890538645\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3932785437958115\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3936274910785085\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.392892340182624\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.3926962106708096\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.3933591102075285\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.3934894025495634\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.3926521594982433\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3935718668008037\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.39323044386198\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.392554189469341\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.3936333622154988\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.3929121595626799\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3932281001299303\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3929123232804062\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.3935098993805393\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.393007903083153\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3930461172478903\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.3929232184525548\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.392435527734938\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.3933564109756156\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.3926783550716608\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.3931701049238472\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.393070619134191\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.3927184825022674\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.3925684931870885\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3928108857119903\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3928434038531639\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.3933427471693471\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.3926468937232657\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.392099649602789\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.3935971355539385\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.3920585163899581\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3930110243553675\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.3927191220340056\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.3931884698537265\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.3923874586969633\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.3922250886265368\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.3931878788049974\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.3926425463494014\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.3925462303806075\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.3927313914746473\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.3921332247309186\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.392958359873793\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.39231223686186\n",
      "Epoch: 687, Iteration: 1/2, Loss: 1.3933867869635133\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.392067411698691\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.3926703609203752\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.3925468934627792\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.3922474507953733\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.3930931274708644\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.3923304373718306\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.3919447524517068\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.393014425799295\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.3919857236859596\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.39280206390047\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.392435295133425\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.3925681626744257\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3922604256885547\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.3925723333276971\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3923740032621454\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.3921799866061189\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.3927471771490956\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3921162285960484\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.3923384690492024\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3919198294507942\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.3922511065739578\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.3927687924621956\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3918222196274892\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.392972935975789\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3917192753722247\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.3927947518212986\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3920714730757053\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.392495328476452\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3921982115768659\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.3918055014603263\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.392647365292879\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.39139206267462\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3925753572856947\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.391746287566583\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.3921583840036988\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.3927459674868259\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3917676470514952\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.3921322842925643\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3925176328101112\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3917801358537587\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.3923567770194032\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.391674456113233\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.3919870083587242\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3920519402215827\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.3924678179661485\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.3916572212039862\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.3919409487864547\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3920511251149468\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.3922342065270619\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.392065490558661\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.3916418798008272\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.3922591546668603\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3914835681426438\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3916265996762514\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.3924056161301381\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3921366277965248\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.3918088990276218\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.3912949442345104\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3925915280919496\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3915485154640663\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.3918463983172673\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.3918508256516522\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.391769589191829\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.3913854793973945\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.391863176800734\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.3920630483223073\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3922226522944094\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3913071207270216\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.3918789541344943\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3917541562487088\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.3919432937798384\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.3915655109339258\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.391676411211825\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3919920843079814\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.3913416184193217\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3916848004276647\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3914768346754722\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3918727094857113\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.3916542385808826\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3913560696580545\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.3922077081188737\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3913909541801894\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.3913008292499258\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.391608164421093\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.3922226505620237\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.3912729774606445\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3916720216036713\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3915139267015495\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3915209609527388\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.391542664716126\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3911757667104716\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.3919695471511162\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.3914446966715928\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.3918274151201389\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3908730105057527\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3920268338214081\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.3908894275833086\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3918332663408577\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.3910999345674913\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.392039508520781\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.3911784406402714\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.3913928829380982\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3915512025331518\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.391676159848067\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.391180158213372\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.39107932297998\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.3919657524917883\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.3909505226267238\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.391793293264713\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3913186496396077\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.3906892833801057\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.3916874967584683\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3910402231587045\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3916136151292766\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.391608416099714\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3910853047488305\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.3911497223442306\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3912718744790282\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.391670607038696\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3909998102498065\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.3910045248971903\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.3916902220813856\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.390936874595291\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.391661154569483\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.3905831443156593\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3915682738625592\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.3910859355253864\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.3911842793090017\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.3914927293330661\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.3909313716854035\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3911750692388405\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.3909004935845677\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.3914884555829958\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.3908992641462175\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3916865895362638\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.3904656353589797\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.3911607969023736\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3913596829307462\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.3912395803583641\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.3912907865491875\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3907275253918854\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.391442165635422\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.3907996518035048\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.3910127825252103\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.3913946570043576\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.3907267589532601\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.3911058361870379\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.3909953996944968\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.390958635992937\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.391167688249201\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.3906385550437275\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.391492905685082\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.3908541122137272\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.390833766880826\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3912639302162009\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3907309440354743\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.390925646554324\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.3909380745522961\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.3910740058264124\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.391171279397775\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.3907295815710725\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3907731214294492\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3909336686710527\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3908716399522616\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3912585441941179\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.3905802805909135\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.390883862675655\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.390594046106017\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.3908685918296984\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.39089598937709\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3911326804754642\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3908450732937354\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.3910940825069997\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3904907388566505\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3909340985496965\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.3907806812824133\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.3910078532333683\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.390539765109731\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.3906623735578463\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.3910276448649597\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3907296887936362\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.3908390049378094\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.3906211178835177\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.3905325912480304\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.391321559017149\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3907762588023584\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.3901801476729156\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.3909779252220784\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.390694175392993\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.3910102289554402\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.3906323587467284\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3905049549881041\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3907256685813063\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.390578610578695\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.3904923658411648\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.390998377993668\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.390631676528284\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3906720033804387\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.390868643310794\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3906292372644222\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.3902022115896622\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.3907891640427155\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3904651541595288\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.3908331610642022\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.3905043097375205\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3906030690426747\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.3905962794859283\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3908508425650283\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.3901543890133037\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3907759648985831\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3905692875019737\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.3906664007415879\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.3907504751873931\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.3903548397723782\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3902273740026154\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3906078844343117\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.3907552538248245\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3905228496104174\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.390502120667038\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.3904532150382676\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3908154146690794\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.3899761346244457\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3909645066679515\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.3902437239934335\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.390453362390317\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.39026339193019\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.3904653848373583\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3906973438596948\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.390475998610396\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3903586767944742\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.3906767441061665\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.3905024493672178\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.3899020469983123\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.3905211218067395\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.3908376417237895\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.3901585884059084\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.3904016689018184\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.3903268124236687\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3905343060462791\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.390352008665372\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.3903087559407379\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.390340583641167\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.39039625805441\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3906579717208412\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.390053802131409\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.390131797369719\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.3903110351811407\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3903351758408642\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.3904267169556774\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3904552526049831\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.3905961524106085\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.3903405240632525\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.39030445261346\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.390026573657969\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.3900291018477098\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3905584911927626\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.390054233050901\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.3904725478049254\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.3902554985945013\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.3903594370008854\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.3899803230934373\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.3907379098923756\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.3902459336661108\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.3898082462060788\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.3906663553802094\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.3899620263419594\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3902825847689668\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3904238371793243\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.3897317366631021\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3901928537728623\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.3903935760802315\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.3902075936036224\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.3902193854302676\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.3902182886993277\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3901143794045594\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.3901586367637218\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3902093855479467\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.390386066828758\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.389698597923335\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.3904172931561816\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3900818116996254\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.3903911390216586\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.390069650875398\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3899694088945058\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.3901227098969295\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3900456775828371\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.390017654887224\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.390043644049866\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.3900736268472262\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3901243121031746\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3900909643350934\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3902716766577607\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.389956936625294\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3900256841225445\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3905013161154458\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.389681691485619\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3902713516232832\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.3899964137328686\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3901046426532349\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.3899860548071228\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.390004223353026\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.3901219950553072\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.38994955528243\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.3902665996708232\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.3895781001849665\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.390255936593403\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.3900182800713499\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.38998937163929\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.3902163203132312\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.3897095198470844\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.3902397927756707\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3897408987483226\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3899947108584803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(len(word2idx), hidden_size, window_size)\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". [-0.02104972  0.0160558   0.01488748 -0.00902945 -0.01703968]\n",
      "am [-2.1066048  -0.18309624 -0.58661705 -1.7736628   0.33806205]\n",
      "studying [ 1.2546953  -1.6356769   1.5718917  -1.2123983   0.36087835]\n",
      "i [-0.00874478 -0.00774224  0.00751108 -0.0028715   0.00498274]\n",
      "now [-0.6636539   0.21635652 -0.37370643  2.0742426  -1.7138873 ]\n",
      "processing [1.4679385  1.8523949  0.03081351 0.7691914  1.3991402 ]\n",
      "language [ 0.6481037  -2.3686128   0.61162436  1.3291777  -1.1303934 ]\n",
      "natural [-0.24834062  2.0332856  -1.9307452  -1.139497    0.7099215 ]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "word_vecs = skip_gram.word_vecs\n",
    "for word_id, word in idx2word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
