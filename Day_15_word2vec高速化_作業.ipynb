{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Pf_RxOIAYv"
   },
   "source": [
    "### 作業目的: 透過實作加速版word2vec Skip-gram模型來更加了解高速版的word2vec\n",
    "\n",
    "本次作業會採用Penn Tree Bank資料及，學員可以在ptb.train.txt中取得訓練文本資料。這次作業可以讓學員練習到以pytorch搭建模型與進行文本資料的前處理\n",
    "\n",
    "PS: 建議學員使用Colab (或可以使用GPU加速的機器)來進行作業，不然訓練會訓練到天荒地老....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO-a6e2OI5zg"
   },
   "source": [
    "### Connect to Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKKpFV6GJwhs"
   },
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4149,
     "status": "ok",
     "timestamp": 1606320764926,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "Yjz-fWmbJRPB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import urllib.request\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3426,
     "status": "ok",
     "timestamp": 1606320764930,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "i9xrgPu3KBgJ",
    "outputId": "341dcbac-256c-45ee-ed8d-3ee0c1fb03b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 42068 lines\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料\n",
    "\n",
    "# Penn Tree Back dataset\n",
    "with open(\"ptb.train.txt\", encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"Total {len(lines)} lines\")\n",
    "raw_dataset = [line.split() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2988,
     "status": "ok",
     "timestamp": 1606320764931,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "oAcF_5CQKH_J",
    "outputId": "b42ef993-9894-4061-f8df-3f929fe17114"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aer',\n",
       "  'banknote',\n",
       "  'berlitz',\n",
       "  'calloway',\n",
       "  'centrust',\n",
       "  'cluett',\n",
       "  'fromstein',\n",
       "  'gitano',\n",
       "  'guterman',\n",
       "  'hydro-quebec',\n",
       "  'ipo',\n",
       "  'kia',\n",
       "  'memotec',\n",
       "  'mlx',\n",
       "  'nahb',\n",
       "  'punts',\n",
       "  'rake',\n",
       "  'regatta',\n",
       "  'rubens',\n",
       "  'sim',\n",
       "  'snack-food',\n",
       "  'ssangyong',\n",
       "  'swapo',\n",
       "  'wachter'],\n",
       " ['pierre',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'will',\n",
       "  'join',\n",
       "  'the',\n",
       "  'board',\n",
       "  'as',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'nov.',\n",
       "  'N'],\n",
       " ['mr.',\n",
       "  '<unk>',\n",
       "  'is',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  '<unk>',\n",
       "  'n.v.',\n",
       "  'the',\n",
       "  'dutch',\n",
       "  'publishing',\n",
       "  'group'],\n",
       " ['rudolph',\n",
       "  '<unk>',\n",
       "  'N',\n",
       "  'years',\n",
       "  'old',\n",
       "  'and',\n",
       "  'former',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  'consolidated',\n",
       "  'gold',\n",
       "  'fields',\n",
       "  'plc',\n",
       "  'was',\n",
       "  'named',\n",
       "  'a',\n",
       "  'nonexecutive',\n",
       "  'director',\n",
       "  'of',\n",
       "  'this',\n",
       "  'british',\n",
       "  'industrial',\n",
       "  'conglomerate'],\n",
       " ['a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'asbestos',\n",
       "  'once',\n",
       "  'used',\n",
       "  'to',\n",
       "  'make',\n",
       "  'kent',\n",
       "  'cigarette',\n",
       "  'filters',\n",
       "  'has',\n",
       "  'caused',\n",
       "  'a',\n",
       "  'high',\n",
       "  'percentage',\n",
       "  'of',\n",
       "  'cancer',\n",
       "  'deaths',\n",
       "  'among',\n",
       "  'a',\n",
       "  'group',\n",
       "  'of',\n",
       "  'workers',\n",
       "  'exposed',\n",
       "  'to',\n",
       "  'it',\n",
       "  'more',\n",
       "  'than',\n",
       "  'N',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'researchers',\n",
       "  'reported']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看前5筆\n",
    "raw_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3502,
     "status": "ok",
     "timestamp": 1606320765980,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "3oki6AxhJyj4",
    "outputId": "79a06d23-2176-4600-b55b-033dfb81ce49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subsampling: 885720 words\n",
      "After subsampling: 437103 words\n"
     ]
    }
   ],
   "source": [
    "# 定義資料前處理函示\n",
    "class PreProcessor():\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    min_freq: int\n",
    "        minimum frequency of a word to be kept\n",
    "    do_subsampling: bool\n",
    "        whether to do subsampling\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, only_word: bool=False, min_freq: int=5, do_subsampling: bool=True, t: float=1e-5):\n",
    "        self.only_word = only_word\n",
    "        self.min_freq = min_freq\n",
    "        self.do_subsampling = do_subsampling\n",
    "        self.t = t\n",
    "    \n",
    "    def process(self, corpus: List[str]):\n",
    "        \n",
    "        word_dic = set()\n",
    "        counter = Counter()\n",
    "        processed_sentence = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "        \n",
    "            # hint: 請計算字詞頻率\n",
    "            counter.update(sentence)\n",
    "            processed_sentence.append(sentence)\n",
    "            ### <your code> ###\n",
    "    \n",
    "        # hint: 移除頻率過小的字詞 建立word2idx與idx2word與word_frequency辭典\n",
    "        word_cnt = dict(filter(lambda x: x[1] > self.min_freq, counter.items()))\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(word_cnt.keys(), 0)}\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        self.word_frequency = word_cnt.copy()\n",
    "        \n",
    "        #將文本轉為ID型式與移除文本中頻率過小的文字\n",
    "        self.processed_corpus = [[self.word2idx[word] for word in line if word in self.word2idx] for line in processed_sentence]\n",
    "        self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
    "        print(f\"Before subsampling: {self.total_num_words} words\")\n",
    "        \n",
    "        # 進行二次採樣(subsampling)\n",
    "        if self.do_subsampling:\n",
    "            self.processed_corpus = [[idx for idx in line if self.subsampling(idx)] for line in self.processed_corpus]\n",
    "            self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
    "            counter = Counter([self.idx2word[idx] for line in self.processed_corpus for idx in line])\n",
    "            word_cnt = dict(counter.items())\n",
    "            self.word_frequency = word_cnt.copy()\n",
    "            ### <your code> ###\n",
    "            print(f\"After subsampling: {self.total_num_words} words\")\n",
    "        \n",
    "        # hint: 移除空字串\n",
    "        self.processed_corpus = [[idx for idx in line] for line in self.processed_corpus if len(line) != 0]\n",
    "        \n",
    "        return self.processed_corpus, self.word2idx, self.idx2word, self.word_frequency, self.total_num_words\n",
    "    \n",
    "    def subsampling(self, idx):\n",
    "        \n",
    "        # hint: 學員可以參考講義的subsampling公式(也可自己定義一個)\n",
    "        \n",
    "        ### <your code> ###\n",
    "        p = self.t / self.word_frequency[self.idx2word[idx]] * self.total_num_words\n",
    "        p_w = math.sqrt(p) + p\n",
    "        return random.uniform(0, 1) < p_w\n",
    "\n",
    "\n",
    "# 進行資料前處理\n",
    "# 這邊我們subsampling的t取1e-4\n",
    "pre_processor = PreProcessor(True, 5, True, 1e-4)\n",
    "corpus, word2idx, idx2word, word2freq, total_num_words = pre_processor.process(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfDuJuT5Kkvl"
   },
   "source": [
    "### 定義Skip-gram使用的Dataset與collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1905,
     "status": "ok",
     "timestamp": 1606320765981,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "DraniEYMKfWl"
   },
   "outputs": [],
   "source": [
    "# 客製化Dataset\n",
    "class SkipGramGetAllDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, corpus, word2freq, word2idx, idx2word, window_size, num_negatives):\n",
    "        self.corpus = corpus\n",
    "        self.word2freq = word2freq\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.window_size = window_size\n",
    "        self.num_negatives = num_negatives\n",
    "        \n",
    "        self.all_targets, self.all_contexts = self._get_all_contexts_targets()\n",
    "        self.all_negatives = self._get_all_negatives()\n",
    "        \n",
    "    def __len__(self):\n",
    "        ### <your code> ###\n",
    "        return len(self.all_targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # hint: 這裡我們會返回 目標字詞，上下文，負採樣樣本\n",
    "        return (self.all_targets[idx],self.all_contexts[idx],self.all_negatives[idx])\n",
    "        \n",
    "    \n",
    "    def _get_all_contexts_targets(self):\n",
    "        all_targets = []\n",
    "        all_contexts = []\n",
    "        \n",
    "        for line in self.corpus:\n",
    "            if len(line) < 2*self.window_size + 1:\n",
    "                continue\n",
    "            \n",
    "            # hint: 這邊我們要創建上下文 (考慮window_size)\n",
    "            ### <your code> ###\n",
    "            all_contexts+=line[self.window_size:-self.window_size]\n",
    "            \n",
    "            for index in range(self.window_size, len(line) - self.window_size):\n",
    "                # hint: 創建目標字詞\n",
    "                indices = list(range(max(0, index - self.window_size), min(len(line), index + self.window_size + 1)))\n",
    "                indices.remove(index)\n",
    "                all_targets.append([line[idx] for idx in indices])\n",
    "                               \n",
    "        return all_targets, all_contexts\n",
    "                               \n",
    "    \n",
    "    def _get_all_negatives(self):\n",
    "        \n",
    "        # hint: 進行負採樣，若沒頭緒的學員可以參考實作範例\n",
    "        \n",
    "        cur_exists_words = list(self.word2freq.keys())\n",
    "        sampling_weights = [self.word2freq[word]**0.75 for word in cur_exists_words]\n",
    "        population = list(range(len(sampling_weights)))\n",
    "        \n",
    "        all_negatives = []\n",
    "        neg_candidate = []\n",
    "        i = 0\n",
    "        for targets in self.all_targets:\n",
    "            ### <your code> ###\n",
    "            negatives = []\n",
    "            while len(negatives) < self.num_negatives:  \n",
    "                if i == len(neg_candidate):\n",
    "                    neg_candidate = random.choices(population, sampling_weights, k=100000)\n",
    "                    neg_candidate = list(map(lambda x: self.word2idx[cur_exists_words[x]], neg_candidate))\n",
    "                    i = 0\n",
    "                if neg_candidate[i] != targets:\n",
    "                    negatives.append(neg_candidate[i])\n",
    "                i += 1\n",
    "            all_negatives.append(negatives)\n",
    "        \n",
    "        return all_negatives\n",
    "    \n",
    "# 客製化collate_fn\n",
    "def skipgram_collate(data):\n",
    "    contexts = []\n",
    "    target_negative = []\n",
    "    labels = []\n",
    "    for target, context, negative in data:\n",
    "        # hint: 將目標字詞、上下文與負採樣樣本個別打包\n",
    "        ### <your code> ###\n",
    "        contexts += [context]\n",
    "        target_negative += [target + negative]\n",
    "        labels += [[1]*len(target) + [0]*len(negative)]\n",
    "    \n",
    "    return torch.tensor(contexts), torch.tensor(target_negative), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s94kJ0lKKzG5"
   },
   "source": [
    "### 定義Skip-gram模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1606320766292,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "kyyQyLxcKpv1"
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        \n",
    "        self.in_embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.out_embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        \n",
    "    def forward(self, contexts, targets):\n",
    "        v = self.in_embedding(contexts).squeeze()#降維\n",
    "        u = self.out_embedding(targets)\n",
    "        \n",
    "        # do dot product to get output\n",
    "        pred = torch.matmul(v[:,None,:], u.permute(0,2,1))\n",
    "        \n",
    "        return pred.squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHZIFz7yK5An"
   },
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 13745,
     "status": "ok",
     "timestamp": 1606320780465,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "Hr4sVBd8K10T"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "verbose = True\n",
    "num_epochs = 100\n",
    "batch_size = 512\n",
    "embed_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "model = SkipGram(len(word2idx), embed_size)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, 2, 5)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=skipgram_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219482,
     "status": "ok",
     "timestamp": 1606321001876,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "sE28LW2_LB0I",
    "outputId": "4cf7c434-b5b8-4e73-eb3c-c2735ef0d17c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Batch: 501/537.15625 Loss: 2.94890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:05<09:06,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 2.88615\n",
      "Epoch: 2/100, Batch: 501/537.15625 Loss: 1.19123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:10<08:52,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100, Loss: 1.18330\n",
      "Epoch: 3/100, Batch: 501/537.15625 Loss: 0.72150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [00:16<08:42,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100, Loss: 0.72280\n",
      "Epoch: 4/100, Batch: 501/537.15625 Loss: 0.56589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:21<08:31,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100, Loss: 0.56851\n",
      "Epoch: 5/100, Batch: 501/537.15625 Loss: 0.49758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [00:26<08:23,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100, Loss: 0.50047\n",
      "Epoch: 6/100, Batch: 501/537.15625 Loss: 0.45767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:31<08:17,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100, Loss: 0.46058\n",
      "Epoch: 7/100, Batch: 501/537.15625 Loss: 0.42911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:36<08:09,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100, Loss: 0.43208\n",
      "Epoch: 8/100, Batch: 501/537.15625 Loss: 0.40638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [00:42<08:02,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100, Loss: 0.40925\n",
      "Epoch: 9/100, Batch: 501/537.15625 Loss: 0.38766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:47<07:58,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100, Loss: 0.39056\n",
      "Epoch: 10/100, Batch: 501/537.15625 Loss: 0.37157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [00:52<07:50,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100, Loss: 0.37463\n",
      "Epoch: 11/100, Batch: 501/537.15625 Loss: 0.35779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [00:57<07:44,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100, Loss: 0.36061\n",
      "Epoch: 12/100, Batch: 501/537.15625 Loss: 0.34538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [01:03<07:40,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100, Loss: 0.34812\n",
      "Epoch: 13/100, Batch: 501/537.15625 Loss: 0.33503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [01:08<07:35,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100, Loss: 0.33787\n",
      "Epoch: 14/100, Batch: 501/537.15625 Loss: 0.32591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [01:13<07:28,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100, Loss: 0.32879\n",
      "Epoch: 15/100, Batch: 501/537.15625 Loss: 0.31790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [01:18<07:23,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100, Loss: 0.32058\n",
      "Epoch: 16/100, Batch: 501/537.15625 Loss: 0.31133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [01:23<07:18,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100, Loss: 0.31400\n",
      "Epoch: 17/100, Batch: 501/537.15625 Loss: 0.30533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [01:29<07:12,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100, Loss: 0.30804\n",
      "Epoch: 18/100, Batch: 501/537.15625 Loss: 0.30024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [01:34<07:06,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100, Loss: 0.30284\n",
      "Epoch: 19/100, Batch: 501/537.15625 Loss: 0.29555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [01:39<07:03,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100, Loss: 0.29819\n",
      "Epoch: 20/100, Batch: 501/537.15625 Loss: 0.29189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [01:44<06:56,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100, Loss: 0.29434\n",
      "Epoch: 21/100, Batch: 501/537.15625 Loss: 0.28805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [01:50<06:56,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100, Loss: 0.29064\n",
      "Epoch: 22/100, Batch: 501/537.15625 Loss: 0.28531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [01:55<06:51,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100, Loss: 0.28776\n",
      "Epoch: 23/100, Batch: 501/537.15625 Loss: 0.28193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [02:00<06:43,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100, Loss: 0.28434\n",
      "Epoch: 24/100, Batch: 501/537.15625 Loss: 0.27967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [02:05<06:37,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100, Loss: 0.28215\n",
      "Epoch: 25/100, Batch: 501/537.15625 Loss: 0.27716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [02:11<06:32,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100, Loss: 0.27941\n",
      "Epoch: 26/100, Batch: 501/537.15625 Loss: 0.27528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [02:16<06:27,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100, Loss: 0.27764\n",
      "Epoch: 27/100, Batch: 501/537.15625 Loss: 0.27307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [02:21<06:22,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100, Loss: 0.27554\n",
      "Epoch: 28/100, Batch: 501/537.15625 Loss: 0.27129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 28/100 [02:26<06:16,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100, Loss: 0.27337\n",
      "Epoch: 29/100, Batch: 501/537.15625 Loss: 0.27017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [02:32<06:12,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100, Loss: 0.27230\n",
      "Epoch: 30/100, Batch: 501/537.15625 Loss: 0.26804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [02:37<06:06,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100, Loss: 0.27053\n",
      "Epoch: 31/100, Batch: 501/537.15625 Loss: 0.26688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [02:42<06:00,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100, Loss: 0.26913\n",
      "Epoch: 32/100, Batch: 501/537.15625 Loss: 0.26572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [02:47<05:55,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100, Loss: 0.26772\n",
      "Epoch: 33/100, Batch: 501/537.15625 Loss: 0.26424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [02:52<05:49,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100, Loss: 0.26672\n",
      "Epoch: 34/100, Batch: 501/537.15625 Loss: 0.26356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [02:58<05:44,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100, Loss: 0.26583\n",
      "Epoch: 35/100, Batch: 501/537.15625 Loss: 0.26268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [03:03<05:39,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100, Loss: 0.26481\n",
      "Epoch: 36/100, Batch: 501/537.15625 Loss: 0.26142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [03:08<05:34,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100, Loss: 0.26360\n",
      "Epoch: 37/100, Batch: 501/537.15625 Loss: 0.26064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [03:13<05:28,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100, Loss: 0.26290\n",
      "Epoch: 38/100, Batch: 501/537.15625 Loss: 0.25946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [03:18<05:23,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100, Loss: 0.26153\n",
      "Epoch: 39/100, Batch: 501/537.15625 Loss: 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [03:24<05:18,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100, Loss: 0.26119\n",
      "Epoch: 40/100, Batch: 501/537.15625 Loss: 0.25798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 40/100 [03:29<05:13,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100, Loss: 0.26029\n",
      "Epoch: 41/100, Batch: 501/537.15625 Loss: 0.25712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [03:34<05:07,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100, Loss: 0.25957\n",
      "Epoch: 42/100, Batch: 501/537.15625 Loss: 0.25650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 42/100 [03:40<05:09,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100, Loss: 0.25888\n",
      "Epoch: 43/100, Batch: 501/537.15625 Loss: 0.25588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [03:45<05:02,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100, Loss: 0.25819\n",
      "Epoch: 44/100, Batch: 501/537.15625 Loss: 0.25572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [03:50<04:55,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100, Loss: 0.25780\n",
      "Epoch: 45/100, Batch: 501/537.15625 Loss: 0.25454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [03:55<04:50,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100, Loss: 0.25681\n",
      "Epoch: 46/100, Batch: 501/537.15625 Loss: 0.25444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [04:01<04:44,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100, Loss: 0.25665\n",
      "Epoch: 47/100, Batch: 501/537.15625 Loss: 0.25403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [04:06<04:38,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100, Loss: 0.25600\n",
      "Epoch: 48/100, Batch: 501/537.15625 Loss: 0.25346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 48/100 [04:11<04:34,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100, Loss: 0.25551\n",
      "Epoch: 49/100, Batch: 501/537.15625 Loss: 0.25290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [04:16<04:28,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100, Loss: 0.25517\n",
      "Epoch: 50/100, Batch: 501/537.15625 Loss: 0.25272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [04:22<04:22,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100, Loss: 0.25482\n",
      "Epoch: 51/100, Batch: 501/537.15625 Loss: 0.25203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [04:27<04:17,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100, Loss: 0.25427\n",
      "Epoch: 52/100, Batch: 501/537.15625 Loss: 0.25161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 52/100 [04:32<04:13,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100, Loss: 0.25378\n",
      "Epoch: 53/100, Batch: 501/537.15625 Loss: 0.25074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [04:37<04:07,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100, Loss: 0.25325\n",
      "Epoch: 54/100, Batch: 501/537.15625 Loss: 0.25080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [04:43<04:01,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100, Loss: 0.25310\n",
      "Epoch: 55/100, Batch: 501/537.15625 Loss: 0.25062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [04:48<03:56,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100, Loss: 0.25267\n",
      "Epoch: 56/100, Batch: 501/537.15625 Loss: 0.25015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [04:53<03:50,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100, Loss: 0.25220\n",
      "Epoch: 57/100, Batch: 501/537.15625 Loss: 0.24972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [04:58<03:45,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100, Loss: 0.25176\n",
      "Epoch: 58/100, Batch: 501/537.15625 Loss: 0.24942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 58/100 [05:04<03:40,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100, Loss: 0.25155\n",
      "Epoch: 59/100, Batch: 501/537.15625 Loss: 0.24909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [05:09<03:35,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100, Loss: 0.25129\n",
      "Epoch: 60/100, Batch: 501/537.15625 Loss: 0.24861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 60/100 [05:14<03:29,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100, Loss: 0.25105\n",
      "Epoch: 61/100, Batch: 501/537.15625 Loss: 0.24872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [05:19<03:24,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100, Loss: 0.25107\n",
      "Epoch: 62/100, Batch: 501/537.15625 Loss: 0.24827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [05:25<03:21,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100, Loss: 0.25025\n",
      "Epoch: 63/100, Batch: 501/537.15625 Loss: 0.24807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [05:30<03:15,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100, Loss: 0.25002\n",
      "Epoch: 64/100, Batch: 501/537.15625 Loss: 0.24755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [05:35<03:09,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100, Loss: 0.24958\n",
      "Epoch: 65/100, Batch: 501/537.15625 Loss: 0.24722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [05:41<03:04,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100, Loss: 0.24941\n",
      "Epoch: 66/100, Batch: 501/537.15625 Loss: 0.24726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [05:46<02:58,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100, Loss: 0.24942\n",
      "Epoch: 67/100, Batch: 501/537.15625 Loss: 0.24720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [05:51<02:52,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100, Loss: 0.24933\n",
      "Epoch: 68/100, Batch: 501/537.15625 Loss: 0.24651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [05:56<02:48,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100, Loss: 0.24871\n",
      "Epoch: 69/100, Batch: 501/537.15625 Loss: 0.24677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [06:02<02:42,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100, Loss: 0.24899\n",
      "Epoch: 70/100, Batch: 501/537.15625 Loss: 0.24567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 70/100 [06:07<02:37,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100, Loss: 0.24806\n",
      "Epoch: 71/100, Batch: 501/537.15625 Loss: 0.24633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [06:12<02:32,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100, Loss: 0.24835\n",
      "Epoch: 72/100, Batch: 501/537.15625 Loss: 0.24566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 72/100 [06:17<02:27,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100, Loss: 0.24793\n",
      "Epoch: 73/100, Batch: 501/537.15625 Loss: 0.24559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [06:23<02:21,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100, Loss: 0.24803\n",
      "Epoch: 74/100, Batch: 501/537.15625 Loss: 0.24528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [06:28<02:16,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100, Loss: 0.24737\n",
      "Epoch: 75/100, Batch: 501/537.15625 Loss: 0.24524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [06:33<02:11,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100, Loss: 0.24723\n",
      "Epoch: 76/100, Batch: 501/537.15625 Loss: 0.24544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [06:38<02:06,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100, Loss: 0.24750\n",
      "Epoch: 77/100, Batch: 501/537.15625 Loss: 0.24504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [06:44<02:00,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100, Loss: 0.24730\n",
      "Epoch: 78/100, Batch: 501/537.15625 Loss: 0.24497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 78/100 [06:49<01:56,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100, Loss: 0.24679\n",
      "Epoch: 79/100, Batch: 501/537.15625 Loss: 0.24435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [06:54<01:50,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100, Loss: 0.24666\n",
      "Epoch: 80/100, Batch: 501/537.15625 Loss: 0.24450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [06:59<01:45,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100, Loss: 0.24659\n",
      "Epoch: 81/100, Batch: 501/537.15625 Loss: 0.24462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [07:05<01:40,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100, Loss: 0.24686\n",
      "Epoch: 82/100, Batch: 501/537.15625 Loss: 0.24440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 82/100 [07:10<01:34,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100, Loss: 0.24622\n",
      "Epoch: 83/100, Batch: 501/537.15625 Loss: 0.24387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [07:16<01:31,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100, Loss: 0.24587\n",
      "Epoch: 84/100, Batch: 501/537.15625 Loss: 0.24380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [07:21<01:25,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100, Loss: 0.24617\n",
      "Epoch: 85/100, Batch: 501/537.15625 Loss: 0.24348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [07:26<01:19,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100, Loss: 0.24553\n",
      "Epoch: 86/100, Batch: 501/537.15625 Loss: 0.24320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [07:31<01:13,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100, Loss: 0.24533\n",
      "Epoch: 87/100, Batch: 501/537.15625 Loss: 0.24349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [07:37<01:08,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100, Loss: 0.24563\n",
      "Epoch: 88/100, Batch: 501/537.15625 Loss: 0.24293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 88/100 [07:42<01:03,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100, Loss: 0.24528\n",
      "Epoch: 89/100, Batch: 501/537.15625 Loss: 0.24292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [07:47<00:57,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100, Loss: 0.24525\n",
      "Epoch: 90/100, Batch: 501/537.15625 Loss: 0.24280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 90/100 [07:52<00:52,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100, Loss: 0.24497\n",
      "Epoch: 91/100, Batch: 501/537.15625 Loss: 0.24252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [07:58<00:47,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100, Loss: 0.24453\n",
      "Epoch: 92/100, Batch: 501/537.15625 Loss: 0.24250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [08:03<00:41,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100, Loss: 0.24471\n",
      "Epoch: 93/100, Batch: 501/537.15625 Loss: 0.24242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [08:08<00:36,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100, Loss: 0.24441\n",
      "Epoch: 94/100, Batch: 501/537.15625 Loss: 0.24192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [08:13<00:31,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100, Loss: 0.24433\n",
      "Epoch: 95/100, Batch: 501/537.15625 Loss: 0.24220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [08:19<00:26,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100, Loss: 0.24458\n",
      "Epoch: 96/100, Batch: 501/537.15625 Loss: 0.24248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [08:24<00:20,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100, Loss: 0.24460\n",
      "Epoch: 97/100, Batch: 501/537.15625 Loss: 0.24201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [08:29<00:15,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100, Loss: 0.24434\n",
      "Epoch: 98/100, Batch: 501/537.15625 Loss: 0.24203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [08:34<00:10,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100, Loss: 0.24410\n",
      "Epoch: 99/100, Batch: 501/537.15625 Loss: 0.24186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [08:40<00:05,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100, Loss: 0.24389\n",
      "Epoch: 100/100, Batch: 501/537.15625 Loss: 0.24232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:45<00:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100, Loss: 0.24411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "lst_loss = []\n",
    "model.train()\n",
    "for epc in tqdm.tqdm(range(num_epochs)):\n",
    "    batch_loss = 0\n",
    "\n",
    "    for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n",
    "        # hint: 開始訓練前要先將optimizer的梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        ### <your code> ###\n",
    "        \n",
    "        if use_cuda:\n",
    "            contexts = contexts.cuda()\n",
    "            target_negative = target_negative.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        pred = model(contexts, target_negative)\n",
    "        loss = criterion(pred.float(), labels.float())\n",
    "        batch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(f\"Epoch: {epc + 1}/{num_epochs}, Batch: {i+1}/{len(dataset)/batch_size} Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Epoch: {epc + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n",
    "    \n",
    "    lst_loss.append(batch_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1606321013487,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "y0rt5W2ELLvP",
    "outputId": "b497edcc-fc8e-47d3-b3ff-c574d42ff581"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization loss\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(lst_loss, marker='s')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Word2Vec Skip-gram Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1606321030038,
     "user": {
      "displayName": "劉冠宏",
      "photoUrl": "",
      "userId": "10277899974318815441"
     },
     "user_tz": -480
    },
    "id": "43pOYRh-MX_F",
    "outputId": "3de0675b-47af-462d-c927-f14a62933956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.386: holidays.\n",
      "cosine sim=0.371: credible.\n",
      "cosine sim=0.353: me.\n",
      "cosine sim=0.347: promotion.\n"
     ]
    }
   ],
   "source": [
    "#計算字詞相似度\n",
    "\n",
    "def get_similarity(word, top_k, model, word2idx, idx2word):\n",
    "    W = (model.in_embedding.weight.data + model.out_embedding.weight.data) / 2\n",
    "    idx = word2idx.get(word, None)\n",
    "    \n",
    "    if not idx:\n",
    "        # 當出現不在字典中的字詞時，顯示Out of vocabulary error\n",
    "        raise ValueError(\"Out of vocabulary\")\n",
    "    else:\n",
    "        x = W[idx]\n",
    "        \n",
    "        # 使用cosine相似計算字詞間的相似程度\n",
    "        cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n",
    "        _, topk = torch.topk(cos, top_k+1)\n",
    "        \n",
    "        for i in topk[1:]:\n",
    "            print(f\"cosine sim={cos[int(i)]:.3f}: {idx2word[int(i)]}.\")\n",
    "\n",
    "get_similarity('love', 4, model, word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_tL9g0oMcCT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNRbZbSHSpiMTWmQCCagSqg",
   "collapsed_sections": [],
   "name": "word2vec高速化_作業解答.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
